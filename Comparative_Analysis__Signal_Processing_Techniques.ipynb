{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/25Iqbalhossain/-Comparative-Analysis-of-AI-and-Signal-Processing-Techniques-for-Power-System-Condition-Monitoring/blob/main/Comparative_Analysis__Signal_Processing_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b84b709"
      },
      "source": [
        "Comparative Analysis of AI and Signal Processing Techniques for Power System Condition Monitoring\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7r_ZDypof6b",
        "outputId": "2637ba38-cf10-4671-aa16-b57e0d32d232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HVTL_YPenfXX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pywt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D4cNH7aozSk",
        "outputId": "254842e3-f18c-4211-8419-145c9f4f0102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " I Use Reference Materials **Dataset ** which  is Given GitHub Repository\n",
        "link: [Datasets ](https://github.com/KingArthur000/Electrical-Fault-detection-and-classification)\n"
      ],
      "metadata": {
        "id": "Md8B6M27hpWh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n1S-lMilnzKp"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "file_path = \"/content/drive/MyDrive/DataSet(Comparative Analysis of AI and Signal Processing Techniques for Power System Condition Monitoring)/classData.csv\"  # Ensure the correct file path\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t37cBV3bn372"
      },
      "outputs": [],
      "source": [
        "# Select numerical features (currents and voltages)\n",
        "X = df[['Ia', 'Ib', 'Ic', 'Va', 'Vb', 'Vc']].values\n",
        "\n",
        "# Assuming \"G\" is the main target variable\n",
        "y = df['G'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99D4PuW_n9cf",
        "outputId": "68dc1fdc-a896-49f0-9f65-51627a7fce00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pywt/_multilevel.py:43: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Wavelet Transform Feature Extraction\n",
        "def wavelet_transform_with_stats(X):\n",
        "    extracted_features = []\n",
        "    for signal in X:\n",
        "        coeffs = pywt.wavedec(signal, 'db4', level=3)  # 3-level wavelet decomposition\n",
        "        features = np.hstack([np.mean(c) for c in coeffs] + [np.std(c) for c in coeffs])\n",
        "        extracted_features.append(features)\n",
        "    return np.array(extracted_features)\n",
        "\n",
        "X_wavelet = wavelet_transform_with_stats(X)\n",
        "\n",
        "# Step 2: Apply PCA for Dimensionality Reduction\n",
        "pca = PCA(n_components=5)  # Keeping 5 principal components\n",
        "X_reduced = pca.fit_transform(X_wavelet)\n",
        "\n",
        "# Step 3: Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnAT_sZQy1lO",
        "outputId": "ffbf7985-a2c3-493c-f723-4e9beb4041fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87       882\n",
            "           1       0.78      0.98      0.87       691\n",
            "\n",
            "    accuracy                           0.87      1573\n",
            "   macro avg       0.88      0.88      0.87      1573\n",
            "weighted avg       0.89      0.87      0.87      1573\n",
            "\n",
            "AUC-ROC Score: 0.88\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train and Compare Multiple Models\n",
        "# ANN Model (MLP Classifier)\n",
        "from sklearn.neural_network import MLPClassifier # Import the MLPClassifier\n",
        "\n",
        "ann = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=500, random_state=42)\n",
        "ann.fit(X_train, y_train)\n",
        "y_pred_ann = ann.predict(X_test)\n",
        "print(\"ANN Performance:\")\n",
        "print(classification_report(y_test, y_pred_ann))\n",
        "print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred_ann):.2f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "436ae9ef",
        "outputId": "a706b08b-27f3-495f-b8ac-69127ccc7517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN Accuracy: 0.8601\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define and train an ANN model\n",
        "ann_model = MLPClassifier(hidden_layer_sizes=(50, 50), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
        "ann_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate ANN\n",
        "y_pred_ann = ann_model.predict(X_test)\n",
        "ann_accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "print(f'ANN Accuracy: {ann_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IrcSA83my8GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee2797b-195a-4fcc-8d8f-882ed4395b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       882\n",
            "           1       0.84      0.86      0.85       691\n",
            "\n",
            "    accuracy                           0.87      1573\n",
            "   macro avg       0.87      0.87      0.87      1573\n",
            "weighted avg       0.87      0.87      0.87      1573\n",
            "\n",
            "AUC-ROC Score: 0.87\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SVM as a Baseline ML Model\n",
        "# Import the necessary class\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVM as a Baseline ML Model\n",
        "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "print(\"SVM Performance:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred_svm):.2f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "clWMyG7eoArH"
      },
      "outputs": [],
      "source": [
        "class SimpleANFIS:\n",
        "    def __init__(self, num_rules=5):\n",
        "        self.num_rules = num_rules\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.random.rand(X.shape[1], self.num_rules)  # Initialize random weights\n",
        "        self.bias = np.random.rand(self.num_rules)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Calculate the weighted sum for each rule\n",
        "        weighted_sum = np.dot(X, self.weights)\n",
        "\n",
        "        # Add bias to the weighted sum and sum across rules\n",
        "        output = np.sum(weighted_sum + self.bias, axis=1)\n",
        "\n",
        "        # Round the output to the nearest integer for classification\n",
        "        return np.round(output).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1FNvIoMSrlpi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# if i use this code SimpleANFIS with a basic gradient descent learning method:\n",
        "# but here epochs 100 we train our model 100 times that why it's decreased\n",
        "#AUC-ROC Score: 0.50 comes which is not good becouse\n",
        "#AUC-ROC Score = 0.50 → The model performs like a random guess (no predictive power).\n",
        "\n",
        "class SimpleANFIS:\n",
        "    def __init__(self, num_rules=5, learning_rate=0.01, epochs=100):\n",
        "        self.num_rules = num_rules\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.random.rand(X.shape[1], self.num_rules)  # Initialize random weights\n",
        "        self.bias = np.random.rand(self.num_rules)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            # Forward pass\n",
        "            weighted_sum = np.dot(X, self.weights)\n",
        "            output = np.sum(weighted_sum + self.bias, axis=1)\n",
        "            predictions = np.round(output).astype(int)\n",
        "\n",
        "            # Calculate error\n",
        "            error = y - predictions\n",
        "\n",
        "            # Backpropagation to update weights and biases\n",
        "            # Note: This is a simplified gradient descent\n",
        "            self.weights += self.learning_rate * np.dot(X.T, error[:, np.newaxis]) / X.shape[0]\n",
        "            self.bias += self.learning_rate * np.sum(error) / X.shape[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        weighted_sum = np.dot(X, self.weights)\n",
        "        output = np.sum(weighted_sum + self.bias, axis=1)\n",
        "        return np.round(output).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "smote = SMOTE()\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Train ANFIS Model with more rules\n",
        "anfis = SimpleANFIS(num_rules=20)  # Increased rules for better learning\n",
        "anfis.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "y_pred = np.round(anfis.predict(X_test_scaled))  # Round predictions to valid class labels\n",
        "y_pred = np.clip(y_pred, 0, 16)  # Ensure predictions stay within valid range\n",
        "\n",
        "print(\"ANFIS Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred):.2f}\")\n",
        "\n",
        "print(\"Unique predictions:\", set(y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSozTr7LaMCM",
        "outputId": "8f255806-d917-4c89-f268-4d5f6350251b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANFIS Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81       882\n",
            "           1       0.73      0.85      0.79       691\n",
            "\n",
            "    accuracy                           0.80      1573\n",
            "   macro avg       0.80      0.80      0.80      1573\n",
            "weighted avg       0.81      0.80      0.80      1573\n",
            "\n",
            "AUC-ROC Score: 0.80\n",
            "Unique predictions: {0, 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, roc_auc_score, balanced_accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.combine import SMOTETomek\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "class RBNN:\n",
        "    def __init__(self, num_centers, feedback_weight=0.5):\n",
        "        self.num_centers = num_centers  # Number of RBF centers\n",
        "        self.feedback_weight = feedback_weight  # Strength of recurrent connection\n",
        "        self.centers = None\n",
        "        self.sigma = None\n",
        "        self.weights = None\n",
        "        self.hidden_state = None  # Stores recurrent hidden state\n",
        "\n",
        "    def rbf_function(self, X):\n",
        "        \"\"\" Compute RBF kernel values with feedback \"\"\"\n",
        "        dist = cdist(X, self.centers)  # Compute Euclidean distance\n",
        "        rbf_out = np.exp(-dist**2 / (2 * self.sigma**2))\n",
        "\n",
        "        # Reset hidden_state for each prediction call\n",
        "        # This ensures that the shape of hidden_state matches the input data during prediction\n",
        "        self.hidden_state = None\n",
        "\n",
        "        if self.hidden_state is not None:\n",
        "            rbf_out += self.feedback_weight * self.hidden_state  # Add recurrent component\n",
        "\n",
        "        self.hidden_state = rbf_out  # Store for next iteration\n",
        "        return rbf_out\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        \"\"\" Train RBNN using KMeans for centers and Logistic Regression for weights \"\"\"\n",
        "        kmeans = KMeans(n_clusters=self.num_centers, random_state=42)\n",
        "        self.centers = kmeans.fit(X_train).cluster_centers_\n",
        "        self.sigma = np.mean([np.linalg.norm(c - self.centers, axis=1) for c in self.centers])\n",
        "\n",
        "        X_rbf = self.rbf_function(X_train)\n",
        "        self.weights = LogisticRegression(max_iter=1000).fit(X_rbf, y_train)  # Train classifier\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\" Predict using RBNN \"\"\"\n",
        "        X_rbf = self.rbf_function(X_test)\n",
        "        return self.weights.predict(X_rbf)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Handle class imbalance with SMOTETomek\n",
        "smote_tomek = SMOTETomek()\n",
        "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Train RBNN Model\n",
        "rbnn = RBNN(num_centers=20, feedback_weight=0.5)  # Adjust the number of RBF centers & feedback\n",
        "rbnn.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Evaluate Model Performance\n",
        "y_pred = rbnn.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nRBNN Performance:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred):.2f}\")\n",
        "print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(\"Unique predictions:\", set(y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXGltDnavW2w",
        "outputId": "93082cb6-3d60-4787-f499-11c1a11225ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RBNN Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87       882\n",
            "           1       0.83      0.85      0.84       691\n",
            "\n",
            "    accuracy                           0.86      1573\n",
            "   macro avg       0.86      0.86      0.86      1573\n",
            "weighted avg       0.86      0.86      0.86      1573\n",
            "\n",
            "AUC-ROC Score: 0.86\n",
            "Balanced Accuracy Score: 0.86\n",
            "Unique predictions: {0, 1}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}